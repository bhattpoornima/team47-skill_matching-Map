# -*- coding: utf-8 -*-
"""team47ml.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XNe6OS-I0VB4XRgSwRTGN2Xvj0x8LT9k
"""

#data cleaning and modification

import pandas as pd
from google.colab import files

# Load dataset
df = pd.read_csv("/content/diversified_rural_criticality.csv")
df.columns = df.columns.str.strip()

# Group and average relevant fields
grouped = df.groupby("Location_ID").agg({
    "Latitude": "mean",
    "Longitude": "mean",
    "Criticality_Score": "mean"
}).reset_index()

# Sort by criticality score (descending)
grouped = grouped.sort_values(by="Criticality_Score", ascending=False)

# Save as JSON (records format is best for reading each row as an object)
grouped.to_json("grouped_lat_lon.json", orient="records", indent=2)

# Download the JSON file
files.download("grouped_lat_lon.json")

"""e5-large-v2 model"""

# Install required library (run this only in Colab or first-time setup)
!pip install -q sentence-transformers

from sentence_transformers import SentenceTransformer, util

# 1. Define the user model
class MockUser:
    def __init__(self, name, is_certified, skills, phone_no):
        self.name = name
        self.is_certified = is_certified
        self.skills = skills
        self.phone_no = phone_no

# 2. New Dummy User Dataset
mock_users = [
    MockUser("Anjali", True, ["Stitching"], "9998887770"),
    MockUser("Ritika", True, ["Computer Course", "Digital Marketing"], "8887776661"),
    MockUser("Sunita", True, ["Parlour", "Stitching"], "7776665552"),
    MockUser("Pooja", True, ["Parlour"], "6665554443"),
    MockUser("Rani", True, ["Digital marketing", "Stitching"], "5554443334"),
    MockUser("Meera", True, ["computer course", "Stitching"], "4443332225"),
    MockUser("Kajal", True, ["Computer Skills", "MS Office"], "3332221116"),
    MockUser("Deepa", True, ["parlour"], "2221110007"),
    MockUser("Tara", True, ["Embroidery", "Sewing"], "1110009998"),
]

# 3. Updated Job Description
job_description = "Looking for someone with ms office and word experience in computer"

# 4. Skill synonyms map
skill_synonyms = {
    "stitching": ["sewing", "tailoring", "pattern making", "hand stitching", "textile"],
    "parlour": ["makeup", "beauty", "spa"],
    "digital marketing": ["social media", "marketing"],
    "computer": ["computer course", "typing", "ms office", "word"]
}

# 5. Load E5 model
model = SentenceTransformer("intfloat/e5-large-v2")

# 6. Matching function
def match_users_to_job(job_description, users, threshold=0.65):
    job_emb = model.encode("query: " + job_description, convert_to_tensor=True)
    matches = []

    job_desc_lower = job_description.lower()
    relevant_keywords = set()
    for key, synonyms in skill_synonyms.items():
        if key in job_desc_lower or any(s in job_desc_lower for s in synonyms):
            relevant_keywords.update(synonyms + [key])

    for user in users:
        if not user.is_certified:
            continue

        user_skills_lower = [s.lower() for s in user.skills]
        if not any(skill in relevant_keywords for skill in user_skills_lower):
            continue  # Skip if no skill matches the job description

        skill_sentence = f"passage: Skilled in {', '.join(user.skills)}"
        user_emb = model.encode(skill_sentence, convert_to_tensor=True)
        score = util.cos_sim(job_emb, user_emb).item()

        if score >= threshold:
            matches.append({
                "name": user.name,
                "phone_no": user.phone_no,
                "skills": user.skills,
                "score": round(score, 3)
            })

    return sorted(matches, key=lambda x: x["score"], reverse=True)

# 7. Run and Print Matches
matched_users = match_users_to_job(job_description, mock_users)
for user in matched_users:
    print(user)